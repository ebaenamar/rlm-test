# RLM Architecture - Visual Guide

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          USER REQUEST                               â”‚
â”‚                                                                     â”‚
â”‚  Query: "What are the main themes in this 200k token document?"   â”‚
â”‚  Context: [huge_document] (200,000 tokens)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RLM.completion(query, context)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      REPL ENVIRONMENT                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Variables:                                                   â”‚ â”‚
â”‚  â”‚  â”œâ”€ context = [200k token document stored in memory]         â”‚ â”‚
â”‚  â”‚  â”œâ”€ result = None                                            â”‚ â”‚
â”‚  â”‚  â””â”€ [other variables created during execution]               â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚  Available Functions:                                         â”‚ â”‚
â”‚  â”‚  â”œâ”€ recursive_lm(query, context_subset)                      â”‚ â”‚
â”‚  â”‚  â”œâ”€ Standard Python: len, str, list, dict, re, json         â”‚ â”‚
â”‚  â”‚  â””â”€ [safe builtins only - no file I/O, network, etc.]       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ROOT LM (Depth = 0)                              â”‚
â”‚                    Model: GPT-4o                                    â”‚
â”‚                                                                     â”‚
â”‚  Receives:                                                          â”‚
â”‚  â”œâ”€ Query: "What are the main themes..."                          â”‚
â”‚  â”œâ”€ System prompt explaining REPL environment                     â”‚
â”‚  â”œâ”€ Context info: type=str, size=200k chars, preview=[first 200] â”‚
â”‚  â””â”€ Max iterations: 10                                            â”‚
â”‚                                                                     â”‚
â”‚  Can do:                                                            â”‚
â”‚  â”œâ”€ Write Python code to analyze context                          â”‚
â”‚  â”œâ”€ Call recursive_lm() for sub-queries                           â”‚
â”‚  â”œâ”€ Store results in variables                                    â”‚
â”‚  â””â”€ Return FINAL(answer) or FINAL_VAR(variable_name)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ITERATION 1       â”‚  â”‚  ITERATION 2     â”‚  ... up to 10
         â”‚                    â”‚  â”‚                  â”‚
         â”‚  Root LM decides:  â”‚  â”‚  Root LM:        â”‚
         â”‚  "I'll peek at     â”‚  â”‚  "Now I'll chunk â”‚
         â”‚   the context"     â”‚  â”‚   and recurse"   â”‚
         â”‚                    â”‚  â”‚                  â”‚
         â”‚  Generates code:   â”‚  â”‚  Generates code: â”‚
         â”‚  ```python         â”‚  â”‚  ```python       â”‚
         â”‚  peek = context[:  â”‚  â”‚  chunks = [      â”‚
         â”‚    1000]           â”‚  â”‚    context[i:i+  â”‚
         â”‚  print(peek)       â”‚  â”‚    10000]        â”‚
         â”‚  ```               â”‚  â”‚    for i in      â”‚
         â”‚                    â”‚  â”‚    range(0,len(  â”‚
         â”‚  â†“ Execute in REPL â”‚  â”‚    context),     â”‚
         â”‚                    â”‚  â”‚    10000)]       â”‚
         â”‚  Result:           â”‚  â”‚  results = []    â”‚
         â”‚  "This document    â”‚  â”‚  for chunk in    â”‚
         â”‚   appears to be    â”‚  â”‚    chunks:       â”‚
         â”‚   about AI and     â”‚  â”‚    r = recursive â”‚
         â”‚   machine          â”‚  â”‚      _lm("themes"â”‚
         â”‚   learning..."     â”‚  â”‚      , chunk)    â”‚
         â”‚                    â”‚  â”‚    results.appendâ”‚
         â”‚  â†“ Feed back to LM â”‚  â”‚      (r)         â”‚
         â”‚                    â”‚  â”‚  ```             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚
                                 â”‚  â†“ Execute       â”‚
                                 â”‚                  â”‚
                                 â”‚  Spawns 20       â”‚
                                 â”‚  recursive calls â”‚
                                 â”‚  â†“               â”‚
                                 â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ RECURSIVE LM #1    â”‚   ...    â”‚ RECURSIVE LM #20   â”‚
         â”‚ (Depth = 1)        â”‚          â”‚ (Depth = 1)        â”‚
         â”‚                    â”‚          â”‚                    â”‚
         â”‚ Model: GPT-4o-mini â”‚          â”‚ Model: GPT-4o-mini â”‚
         â”‚                    â”‚          â”‚                    â”‚
         â”‚ Receives:          â”‚          â”‚ Receives:          â”‚
         â”‚ â”œâ”€ Query: "themes" â”‚          â”‚ â”œâ”€ Query: "themes" â”‚
         â”‚ â””â”€ Context: chunk1 â”‚          â”‚ â””â”€ Context: chunk20â”‚
         â”‚    (10k tokens)    â”‚          â”‚    (10k tokens)    â”‚
         â”‚                    â”‚          â”‚                    â”‚
         â”‚ Returns:           â”‚          â”‚ Returns:           â”‚
         â”‚ "AI ethics,        â”‚          â”‚ "Neural networks,  â”‚
         â”‚  automation"       â”‚          â”‚  deep learning"    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  All results collected back    â”‚
                    â”‚  to REPL environment           â”‚
                    â”‚                                â”‚
                    â”‚  results = [                   â”‚
                    â”‚    "AI ethics, automation",    â”‚
                    â”‚    "Machine learning, ...",    â”‚
                    â”‚    ...                         â”‚
                    â”‚    "Neural networks, ..."      â”‚
                    â”‚  ]                             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ITERATION 3                   â”‚
                    â”‚                                â”‚
                    â”‚  Root LM:                      â”‚
                    â”‚  "I'll combine the results"    â”‚
                    â”‚                                â”‚
                    â”‚  Generates code:               â”‚
                    â”‚  ```python                     â”‚
                    â”‚  all_themes = set()            â”‚
                    â”‚  for r in results:             â”‚
                    â”‚    themes = r.split(", ")      â”‚
                    â”‚    all_themes.update(themes)   â”‚
                    â”‚  final_answer = ", ".join(     â”‚
                    â”‚    sorted(all_themes))         â”‚
                    â”‚  ```                           â”‚
                    â”‚                                â”‚
                    â”‚  Then outputs:                 â”‚
                    â”‚  FINAL_VAR(final_answer)       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FINAL RESULT                                â”‚
â”‚                                                                     â”‚
â”‚  {                                                                  â”‚
â”‚    "answer": "AI ethics, automation, deep learning, machine        â”‚
â”‚               learning, neural networks, ...",                      â”‚
â”‚    "iterations": 3,                                                 â”‚
â”‚    "total_calls": 21,  # 1 root + 20 recursive                    â”‚
â”‚    "repl_history": [...],                                          â”‚
â”‚    "messages": [...]                                               â”‚
â”‚  }                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Execution Flow

### Step-by-Step Breakdown

```
1. USER CALL
   rlm.completion(query, context)
   
2. INITIALIZE REPL
   context stored as variable (NOT in prompt)
   
3. ROOT LM ITERATION 1
   â”œâ”€ Receives: query + context metadata
   â”œâ”€ Decides: "I'll peek at the context"
   â”œâ”€ Generates: Python code to peek
   â”œâ”€ REPL executes code
   â””â”€ Result fed back to Root LM
   
4. ROOT LM ITERATION 2
   â”œâ”€ Receives: previous result
   â”œâ”€ Decides: "I'll chunk and recurse"
   â”œâ”€ Generates: Code to partition + recursive calls
   â”œâ”€ REPL executes code
   â”œâ”€ Spawns 20 RECURSIVE LM calls (depth=1)
   â”‚   â”œâ”€ Each processes 10k token chunk
   â”‚   â”œâ”€ Each returns partial answer
   â”‚   â””â”€ All results collected
   â””â”€ Results fed back to Root LM
   
5. ROOT LM ITERATION 3
   â”œâ”€ Receives: all recursive results
   â”œâ”€ Decides: "I'll combine these"
   â”œâ”€ Generates: Code to merge results
   â”œâ”€ REPL executes code
   â””â”€ Outputs: FINAL_VAR(final_answer)
   
6. RETURN TO USER
   Complete result with answer + metadata
```

## ğŸ­ Comparison: Traditional vs RLM

### Traditional LLM Approach

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SINGLE LLM CALL                         â”‚
â”‚                                                              â”‚
â”‚  Input Prompt (200k tokens):                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ [Entire 200k token document pasted here]              â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚ ... 200,000 tokens of context ...                     â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚ Query: What are the main themes?                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  â†“ Process all at once                                      â”‚
â”‚                                                              â”‚
â”‚  Output:                                                     â”‚
â”‚  "The main themes are..." (often degraded quality)          â”‚
â”‚                                                              â”‚
â”‚  Problems:                                                   â”‚
â”‚  âŒ Context rot - performance degrades                      â”‚
â”‚  âŒ Expensive - pay for all 200k tokens                     â”‚
â”‚  âŒ Limited - can't exceed context window                   â”‚
â”‚  âŒ Black box - can't see how it processes                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RLM Approach

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MULTIPLE SMART CALLS                      â”‚
â”‚                                                              â”‚
â”‚  Root LM sees (2k tokens):                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Query: What are the main themes?                       â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚ Context available as variable:                        â”‚ â”‚
â”‚  â”‚ - Type: string                                        â”‚ â”‚
â”‚  â”‚ - Size: 200,000 characters                            â”‚ â”‚
â”‚  â”‚ - Preview: "This document discusses..."               â”‚ â”‚
â”‚  â”‚                                                        â”‚ â”‚
â”‚  â”‚ You can execute Python code to analyze it.            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  â†“ Root LM strategizes                                      â”‚
â”‚                                                              â”‚
â”‚  Recursive calls (20 Ã— 10k tokens each):                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Call 1: Process chunk 1 (10k tokens)                  â”‚ â”‚
â”‚  â”‚ Call 2: Process chunk 2 (10k tokens)                  â”‚ â”‚
â”‚  â”‚ ...                                                    â”‚ â”‚
â”‚  â”‚ Call 20: Process chunk 20 (10k tokens)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  â†“ Combine results                                          â”‚
â”‚                                                              â”‚
â”‚  Output:                                                     â”‚
â”‚  "The main themes are..." (high quality)                    â”‚
â”‚                                                              â”‚
â”‚  Benefits:                                                   â”‚
â”‚  âœ… No context rot - small chunks                           â”‚
â”‚  âœ… Cheaper - use mini model for recursion                  â”‚
â”‚  âœ… Unlimited - no context window limit                     â”‚
â”‚  âœ… Transparent - see all steps                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§  Strategy Examples

### Strategy 1: Peek â†’ Grep â†’ Recurse

```
Iteration 1: PEEK
â”œâ”€ Code: peek = context[:1000]
â”œâ”€ Discovers: "This is a list of user reviews"
â””â”€ Decision: "I'll grep for ratings"

Iteration 2: GREP
â”œâ”€ Code: ratings = re.findall(r'Rating: (\d)/5', context)
â”œâ”€ Result: [5, 3, 5, 2, 4, 2, 5, 3, 5, 1]
â””â”€ Decision: "I can calculate average directly"

Iteration 3: CALCULATE
â”œâ”€ Code: avg = sum(ratings) / len(ratings)
â”œâ”€ Result: 3.5
â””â”€ Output: FINAL("Average rating: 3.5/5")
```

### Strategy 2: Partition â†’ Map â†’ Reduce

```
Iteration 1: PEEK
â”œâ”€ Code: peek = context[:500]
â”œâ”€ Discovers: "Large document, ~200k chars"
â””â”€ Decision: "I'll partition and recurse"

Iteration 2: PARTITION & MAP
â”œâ”€ Code: 
â”‚   chunks = [context[i:i+10000] for i in range(0, len(context), 10000)]
â”‚   results = [recursive_lm("Extract themes", chunk) for chunk in chunks]
â”œâ”€ Spawns: 20 recursive LM calls
â””â”€ Collects: 20 partial results

Iteration 3: REDUCE
â”œâ”€ Code:
â”‚   all_themes = set()
â”‚   for r in results:
â”‚       all_themes.update(r.split(", "))
â”‚   final = ", ".join(sorted(all_themes))
â””â”€ Output: FINAL_VAR(final)
```

### Strategy 3: Hierarchical Summarization

```
Iteration 1: CHUNK
â”œâ”€ Code: sections = [context[i:i+20000] for i in range(0, len(context), 20000)]
â””â”€ Creates: 10 sections

Iteration 2: SUMMARIZE SECTIONS
â”œâ”€ Code: summaries = [recursive_lm("Summarize", s) for s in sections]
â”œâ”€ Spawns: 10 recursive calls
â””â”€ Gets: 10 section summaries

Iteration 3: COMBINE SUMMARIES
â”œâ”€ Code: final_summary = recursive_lm("Combine these summaries", summaries)
â”œâ”€ Spawns: 1 recursive call
â””â”€ Output: FINAL_VAR(final_summary)
```

## ğŸ“Š Token Flow Analysis

### Traditional Approach (200k context)

```
Single Call:
â”œâ”€ Input: 200,000 tokens Ã— $2.50/1M = $0.50
â”œâ”€ Output: 500 tokens Ã— $10/1M = $0.005
â””â”€ Total: $0.505 per query

Tokens processed: 200,500
API calls: 1
```

### RLM Approach (200k context)

```
Root LM (3 iterations):
â”œâ”€ Call 1: 2,000 tokens input Ã— $2.50/1M = $0.005
â”œâ”€ Call 2: 2,500 tokens input Ã— $2.50/1M = $0.006
â”œâ”€ Call 3: 3,000 tokens input Ã— $2.50/1M = $0.008
â””â”€ Subtotal: $0.019

Recursive LM (20 calls, using GPT-4o-mini):
â”œâ”€ Each call: 10,000 tokens Ã— $0.15/1M = $0.0015
â”œâ”€ 20 calls: 20 Ã— $0.0015 = $0.030
â””â”€ Subtotal: $0.030

Output tokens:
â””â”€ 500 tokens Ã— $0.60/1M = $0.0003

Total: $0.049 per query (10x cheaper!)

Tokens processed: ~207,500
API calls: 23
```

## ğŸ¯ Key Architectural Decisions

### 1. Why REPL Environment?

```
âœ… Programmatic control
âœ… Variable storage
âœ… Code execution
âœ… Function calls (recursive_lm)
âœ… Familiar Python syntax
âœ… Easy to sandbox
```

### 2. Why Recursive Calls?

```
âœ… Parallel processing of chunks
âœ… Use cheaper models for sub-tasks
âœ… Avoid context rot
âœ… Scalable to any size
âœ… Composable strategies
```

### 3. Why Depth = 1?

```
âœ… Sufficient for most tasks
âœ… Simpler to implement
âœ… Easier to debug
âœ… Lower latency
âš ï¸ Can increase for complex tasks
```

### 4. Why Store Context Separately?

```
âœ… Root LM never sees full context
âœ… No context rot
âœ… Unbounded context size
âœ… Efficient token usage
âœ… Adaptive processing
```

## ğŸ”® Future Architecture

### Planned Improvements

```
Current:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Root LM    â”‚ â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â”œâ”€â†’ Sequential execution
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ Recursive 1 â”‚ â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ Recursive 2 â”‚ â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Future:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Root LM    â”‚ â”€â”€â”¬â”€â†’ Async/parallel
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â”œâ”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   â”‚ Recursive 1 â”‚
                  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   â”‚ Recursive 2 â”‚
                  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â””â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Recursive N â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      
Benefits:
âœ… 10x faster
âœ… Better resource utilization
âœ… Prefix caching
```

---

**This architecture enables unbounded context processing with no performance degradation!** ğŸš€
